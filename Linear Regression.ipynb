{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv (\"Downloads/graduate-admissions/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray (data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data [:, 1]\n",
    "labels = data [:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[337. 324. 316. 322. 314. 330. 321. 308. 302. 323. 325. 327. 328. 307.\n",
      " 311. 314. 317. 319. 318. 303. 312. 325. 328. 334. 336. 340. 322. 298.\n",
      " 295. 310. 300. 327. 338. 340. 331. 320. 299. 300. 304. 307. 308. 316.\n",
      " 313. 332. 326. 322. 329. 339. 321. 327. 313. 312. 334. 324. 322. 320.\n",
      " 316. 298. 300. 311. 309. 307. 304. 315. 325. 325. 327. 316. 318. 328.\n",
      " 332. 336. 321. 314. 314. 329. 327. 301. 296. 294. 312. 340. 320. 322.\n",
      " 340. 319. 315. 317. 314. 316. 318. 299. 298. 301. 303. 304. 306. 331.\n",
      " 332. 323. 322. 312. 314. 317. 326. 316. 329. 338. 331. 304. 305. 321.\n",
      " 301. 320. 311. 310. 299. 290. 296. 327. 335. 334. 310. 308. 301. 300.\n",
      " 323. 319. 326. 333. 339. 303. 309. 323. 333. 314. 312. 316. 326. 318.\n",
      " 329. 332. 331. 340. 325. 320. 315. 326. 339. 311. 334. 332. 321. 324.\n",
      " 326. 312. 315. 309. 306. 297. 315. 298. 318. 317. 329. 322. 302. 313.\n",
      " 293. 311. 312. 334. 322. 323. 321. 320. 329. 319. 309. 307. 300. 305.\n",
      " 299. 314. 316. 327. 317. 335. 331. 324. 324. 323. 322. 336. 316. 307.\n",
      " 306. 310. 311. 313. 317. 315. 340. 334. 298. 295. 315. 310. 305. 301.\n",
      " 325. 328. 338. 333. 331. 330. 322. 321. 324. 312. 313. 316. 324. 308.\n",
      " 305. 296. 306. 312. 318. 324. 313. 319. 312. 304. 330. 326. 325. 329.\n",
      " 310. 299. 296. 317. 324. 325. 314. 328. 316. 311. 324. 321. 320. 316.\n",
      " 318. 335. 321. 307. 309. 324. 326. 331. 327. 312. 308. 324. 325. 313.\n",
      " 312. 314. 327. 308. 306. 299. 294. 312. 315. 322. 329. 320. 308. 304.\n",
      " 311. 317. 312. 321. 340. 331. 336. 324. 314. 313. 307. 300. 302. 312.\n",
      " 316. 317. 310. 320. 330. 305. 309. 319. 322. 323. 313. 321. 323. 325.\n",
      " 312. 308. 320. 328. 311. 301. 305. 308. 298. 300. 324. 327. 317. 323.\n",
      " 314. 305. 315. 326. 299. 295. 324. 297. 327. 311. 308. 319. 312. 325.\n",
      " 319. 332. 323. 324. 312. 326. 308. 305. 295. 316. 304. 299. 302. 313.\n",
      " 318. 325. 303. 300. 297. 317. 327. 301. 314. 321. 322. 334. 338. 306.\n",
      " 313. 330. 320. 311. 298. 301. 310. 324. 336. 321. 315. 304. 297. 290.\n",
      " 303. 311. 322. 319. 324. 300. 340. 335. 302. 307. 296. 320. 314. 318.\n",
      " 326. 317. 329. 324. 325. 330. 312. 333.]\n",
      "[0.92 0.76 0.72 0.8  0.65 0.9  0.75 0.68 0.5  0.45 0.52 0.84 0.78 0.62\n",
      " 0.61 0.54 0.66 0.65 0.63 0.62 0.64 0.7  0.94 0.95 0.97 0.94 0.76 0.44\n",
      " 0.46 0.54 0.65 0.74 0.91 0.9  0.94 0.88 0.64 0.58 0.52 0.48 0.46 0.49\n",
      " 0.53 0.87 0.91 0.88 0.86 0.89 0.82 0.78 0.76 0.56 0.78 0.72 0.7  0.64\n",
      " 0.64 0.46 0.36 0.42 0.48 0.47 0.54 0.56 0.52 0.55 0.61 0.57 0.68 0.78\n",
      " 0.94 0.96 0.93 0.84 0.74 0.72 0.74 0.64 0.44 0.46 0.5  0.96 0.92 0.92\n",
      " 0.94 0.76 0.72 0.66 0.64 0.74 0.64 0.38 0.34 0.44 0.36 0.42 0.48 0.86\n",
      " 0.9  0.79 0.71 0.64 0.62 0.57 0.74 0.69 0.87 0.91 0.93 0.68 0.61 0.69\n",
      " 0.62 0.72 0.59 0.66 0.56 0.45 0.47 0.71 0.94 0.94 0.57 0.61 0.57 0.64\n",
      " 0.85 0.78 0.84 0.92 0.96 0.77 0.71 0.79 0.89 0.82 0.76 0.71 0.8  0.78\n",
      " 0.84 0.9  0.92 0.97 0.8  0.81 0.75 0.83 0.96 0.79 0.93 0.94 0.86 0.79\n",
      " 0.8  0.77 0.7  0.65 0.61 0.52 0.57 0.53 0.67 0.68 0.81 0.78 0.65 0.64\n",
      " 0.64 0.65 0.68 0.89 0.86 0.89 0.87 0.85 0.9  0.82 0.72 0.73 0.71 0.71\n",
      " 0.68 0.75 0.72 0.89 0.84 0.93 0.93 0.88 0.9  0.87 0.86 0.94 0.77 0.78\n",
      " 0.73 0.73 0.7  0.72 0.73 0.72 0.97 0.97 0.69 0.57 0.63 0.66 0.64 0.68\n",
      " 0.79 0.82 0.95 0.96 0.94 0.93 0.91 0.85 0.84 0.74 0.76 0.75 0.76 0.71\n",
      " 0.67 0.61 0.63 0.64 0.71 0.82 0.73 0.74 0.69 0.64 0.91 0.88 0.85 0.86\n",
      " 0.7  0.59 0.6  0.65 0.7  0.76 0.63 0.81 0.72 0.71 0.8  0.77 0.74 0.7\n",
      " 0.71 0.93 0.85 0.79 0.76 0.78 0.77 0.9  0.87 0.71 0.7  0.7  0.75 0.71\n",
      " 0.72 0.73 0.83 0.77 0.72 0.54 0.49 0.52 0.58 0.78 0.89 0.7  0.66 0.67\n",
      " 0.68 0.8  0.81 0.8  0.94 0.93 0.92 0.89 0.82 0.79 0.58 0.56 0.56 0.64\n",
      " 0.61 0.68 0.76 0.86 0.9  0.71 0.62 0.66 0.65 0.73 0.62 0.74 0.79 0.8\n",
      " 0.69 0.7  0.76 0.84 0.78 0.67 0.66 0.65 0.54 0.58 0.79 0.8  0.75 0.73\n",
      " 0.72 0.62 0.67 0.81 0.63 0.69 0.8  0.43 0.8  0.73 0.75 0.71 0.73 0.83\n",
      " 0.72 0.94 0.81 0.81 0.75 0.79 0.58 0.59 0.47 0.49 0.47 0.42 0.57 0.62\n",
      " 0.74 0.73 0.64 0.63 0.59 0.73 0.79 0.68 0.7  0.81 0.85 0.93 0.91 0.69\n",
      " 0.77 0.86 0.74 0.57 0.51 0.67 0.72 0.89 0.95 0.79 0.39 0.38 0.34 0.47\n",
      " 0.56 0.71 0.78 0.73 0.82 0.62 0.96 0.96 0.46 0.53 0.49 0.76 0.64 0.71\n",
      " 0.84 0.77 0.89 0.82 0.84 0.91 0.67 0.95]\n"
     ]
    }
   ],
   "source": [
    "print (features)\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (features, labels)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit (X_train.reshape (-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77925857, 0.55387699, 0.54363237, 0.84072628, 0.62558931,\n",
       "       0.63583393, 0.60510008, 0.45143081, 0.83048166, 0.70754625,\n",
       "       0.69730163, 0.64607855, 0.79974781, 0.5026539 , 0.70754625,\n",
       "       0.79974781, 0.54363237, 0.8509709 , 0.80999243, 0.77925857,\n",
       "       0.51289852, 0.6768124 , 0.59485546, 0.5026539 , 0.63583393,\n",
       "       0.66656778, 0.62558931, 0.79974781, 0.6768124 , 0.71779087,\n",
       "       0.94317246, 0.54363237, 0.60510008, 0.62558931, 0.74852472,\n",
       "       0.64607855, 0.65632316, 0.83048166, 0.96366169, 0.55387699,\n",
       "       0.76901396, 0.86121552, 0.78950319, 0.74852472, 0.90219399,\n",
       "       0.75876934, 0.83048166, 0.82023704, 0.88170475, 0.60510008,\n",
       "       0.54363237, 0.5641216 , 0.66656778, 0.5641216 , 0.71779087,\n",
       "       0.62558931, 0.57436622, 0.69730163, 0.80999243, 0.9124386 ,\n",
       "       0.59485546, 0.83048166, 0.82023704, 0.72803549, 0.6768124 ,\n",
       "       0.6768124 , 0.77925857, 0.6768124 , 0.6768124 , 0.61534469,\n",
       "       0.90219399, 0.63583393, 0.53338775, 0.71779087, 0.69730163,\n",
       "       0.72803549, 0.9124386 , 0.80999243, 0.55387699, 0.69730163,\n",
       "       0.57436622, 0.83048166, 0.64607855, 0.75876934, 0.53338775,\n",
       "       0.92268322, 0.75876934, 0.65632316, 0.64607855, 0.6768124 ,\n",
       "       0.80999243, 0.87146013, 0.68705702, 0.69730163, 0.72803549,\n",
       "       0.75876934, 0.9124386 , 0.66656778, 0.87146013, 0.63583393])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedValue = model.predict (X_test.reshape (-1, 1))\n",
    "predictedValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08191866883872834\n"
     ]
    }
   ],
   "source": [
    "error = mean_squared_error (predictedValue, y_test)\n",
    "squaredError = np.sqrt (error)\n",
    "print (squaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
